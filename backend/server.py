from fastapi import FastAPI, APIRouter, HTTPException, Depends, UploadFile, File, Form, Query
from fastapi.responses import StreamingResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
import hashlib
import asyncio
import jwt
from pathlib import Path
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime, timezone, timedelta
import openai
import requests
import json
import io
import pandas as pd
from PIL import Image
import pytesseract
import PyPDF2
import math
from analysis_engine import FinancialAnalysisEngine
from ocr_data_parser import financial_parser
from ai_agents import ai_agents
from comprehensive_financial_analyzer import ComprehensiveFinancialAnalyzer

def make_json_safe(obj):
    """Recursively make an object JSON-safe by replacing inf and nan values"""
    if isinstance(obj, dict):
        return {k: make_json_safe(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [make_json_safe(item) for item in obj]
    elif isinstance(obj, float):
        if math.isinf(obj):
            return 999999.0 if obj > 0 else -999999.0
        elif math.isnan(obj):
            return 0.0
        return obj
    else:
        return obj

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# APIs setup
openai.api_key = os.environ.get('OPENAI_API_KEY')
FMP_API_KEY = os.environ.get('FMP_API_KEY')
JWT_SECRET = os.environ.get('JWT_SECRET')

# Create the main app
app = FastAPI(title="FinClick.AI API", description="Revolutionary Intelligent Financial Analysis System")
api_router = APIRouter(prefix="/api")

security = HTTPBearer()

# Initialize Analysis Engine
analysis_engine = FinancialAnalysisEngine()

# Models
class User(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    email: str
    password_hash: str
    user_type: str  # "subscriber", "admin", "guest"
    subscription_plan: Optional[str] = None
    subscription_status: str = "inactive"
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    last_login: Optional[datetime] = None

class UserLogin(BaseModel):
    email: str
    password: str

class UserRegister(BaseModel):
    email: str
    password: str
    user_type: str = "subscriber"

class Company(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: Optional[str] = None
    name: str
    sector: str
    activity: str
    legal_entity: str
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class FinancialStatement(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    company_id: str
    year: int
    statement_type: str  # "balance_sheet", "income_statement", "cash_flow"
    data: Dict[str, Any]
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class AnalysisRequest(BaseModel):
    company_name: str
    language: str = "ar"
    sector: str
    activity: str
    legal_entity: str
    comparison_level: str
    analysis_years: int
    analysis_types: List[str]

class AnalysisResult(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: str
    company_name: str
    analysis_data: Dict[str, Any]
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

# Helper functions
def hash_password(password: str) -> str:
    return hashlib.sha256(password.encode()).hexdigest()

def verify_password(password: str, hashed_password: str) -> bool:
    return hash_password(password) == hashed_password

def create_jwt_token(user_id: str, email: str, user_type: str) -> str:
    payload = {
        "user_id": user_id,
        "email": email,
        "user_type": user_type,
        "exp": datetime.utcnow() + timedelta(days=30)
    }
    return jwt.encode(payload, JWT_SECRET, algorithm="HS256")

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        payload = jwt.decode(credentials.credentials, JWT_SECRET, algorithms=["HS256"])
        user_id = payload.get("user_id")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid token")
        return payload
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token expired")
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="Invalid token")
# Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙƒÙ…Ø§ Ø·Ù„Ø¨Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
async def initialize_predefined_accounts():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ - 3 Ø£Ù†ÙˆØ§Ø¹ ÙƒÙ…Ø§ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    predefined_accounts = [
        # 1. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø´ØªØ±ÙƒÙŠÙ† (Ø§Ù„Ø£ÙƒØ¨Ø± ÙˆØ§Ù„Ø£ÙˆÙ„)
        {
            "id": "subscriber-finclick-2025",
            "email": "subscriber@finclick.ai",
            "password_hash": hash_password("subscriber123"),
            "user_type": "subscriber",
            "full_name": "Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø´ØªØ±ÙƒÙŠÙ† Ø§Ù„Ø¹Ø§Ù…",
            "subscription_status": "active",
            "created_at": datetime.now(timezone.utc)
        },
        # 2. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© (Ø£ØµØºØ±ØŒ Ù„Ø§ ÙŠØ¸Ù‡Ø± Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)
        {
            "id": "razan-admin-finclick-2025",
            "email": "Razan@FinClick.AI",
            "password_hash": hash_password("RazanFinClickAI@056300"),
            "user_type": "admin",
            "full_name": "Ø±Ø²Ø§Ù† - Ù…Ø¯ÙŠØ±Ø© Ø§Ù„Ù†Ø¸Ø§Ù…",
            "subscription_status": "active",
            "created_at": datetime.now(timezone.utc)
        },
        # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¶ÙŠÙˆÙ (Ø£ØµØºØ±ØŒ Ù„Ø§ ÙŠØ¸Ù‡Ø± Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)
        {
            "id": "guest-finclick-2025",
            "email": "Guest@FinClick.AI",
            "password_hash": hash_password("GuestFinClickAI@123321"),
            "user_type": "guest",
            "full_name": "Ø§Ù„Ø¶ÙŠÙ Ø§Ù„Ø¹Ø§Ù…",
            "subscription_status": "unlimited",
            "created_at": datetime.now(timezone.utc)
        },
        # Ø­Ø³Ø§Ø¨ Ù…Ø¤Ù‚Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        {
            "id": "test-admin-finclick",
            "email": "admin@finclick.ai",
            "password_hash": hash_password("admin123"),
            "user_type": "admin",
            "full_name": "Ø­Ø³Ø§Ø¨ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¤Ù‚Øª",
            "subscription_status": "active",
            "created_at": datetime.now(timezone.utc)
        }
    ]
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
    for account in predefined_accounts:
        existing_user = await db.users.find_one({"email": account["email"]})
        if not existing_user:
            await db.users.insert_one(account)
            logger.info(f"Created predefined account: {account['email']}")
        else:
            logger.info(f"Predefined account already exists: {account['email']}")

# Financial Analysis Functions
def calculate_liquidity_ratios(balance_sheet: Dict, income_statement: Dict) -> Dict:
    """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"""
    current_assets = balance_sheet.get("current_assets", 0)
    current_liabilities = balance_sheet.get("current_liabilities", 0)
    cash = balance_sheet.get("cash", 0)
    inventory = balance_sheet.get("inventory", 0)
    
    ratios = {}
    
    # Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø¬Ø§Ø±ÙŠØ©
    ratios["current_ratio"] = current_assets / current_liabilities if current_liabilities > 0 else 0
    
    # Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
    quick_assets = current_assets - inventory
    ratios["quick_ratio"] = quick_assets / current_liabilities if current_liabilities > 0 else 0
    
    # Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ù‚Ø¯
    ratios["cash_ratio"] = cash / current_liabilities if current_liabilities > 0 else 0
    
    return ratios

def calculate_profitability_ratios(balance_sheet: Dict, income_statement: Dict) -> Dict:
    """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨ Ø§Ù„Ø±Ø¨Ø­ÙŠØ©"""
    revenue = income_statement.get("revenue", 0)
    gross_profit = income_statement.get("gross_profit", 0)
    operating_profit = income_statement.get("operating_profit", 0)
    net_income = income_statement.get("net_income", 0)
    total_assets = balance_sheet.get("total_assets", 0)
    equity = balance_sheet.get("total_equity", 0)
    
    ratios = {}
    
    # Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
    ratios["gross_margin"] = (gross_profit / revenue * 100) if revenue > 0 else 0
    
    # Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„ØªØ´ØºÙŠÙ„ÙŠ
    ratios["operating_margin"] = (operating_profit / revenue * 100) if revenue > 0 else 0
    
    # Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„ØµØ§ÙÙŠ
    ratios["net_margin"] = (net_income / revenue * 100) if revenue > 0 else 0
    
    # Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£ØµÙˆÙ„
    ratios["roa"] = (net_income / total_assets * 100) if total_assets > 0 else 0
    
    # Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ù„ÙƒÙŠØ©
    ratios["roe"] = (net_income / equity * 100) if equity > 0 else 0
    
    return ratios

async def perform_vertical_analysis(financial_data: Dict, language: str = "ar") -> Dict:
    """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£Ø³ÙŠ"""
    balance_sheet = financial_data.get("balance_sheet", {})
    income_statement = financial_data.get("income_statement", {})
    
    total_assets = balance_sheet.get("total_assets", 0)
    revenue = income_statement.get("revenue", 0)
    
    analysis = {
        "title": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£Ø³ÙŠ" if language == "ar" else "Vertical Analysis",
        "description": "ØªØ­Ù„ÙŠÙ„ Ù†Ø³Ø¨Ø© ÙƒÙ„ Ø¨Ù†Ø¯ Ø¥Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£ØµÙˆÙ„ Ø£Ùˆ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª" if language == "ar" else "Analysis of each item as percentage of total assets or revenue",
        "balance_sheet_analysis": {},
        "income_statement_analysis": {}
    }
    
    # ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø§Ù„ÙŠ
    for item, value in balance_sheet.items():
        if item != "total_assets" and total_assets > 0:
            percentage = (value / total_assets) * 100
            analysis["balance_sheet_analysis"][item] = {
                "value": value,
                "percentage": round(percentage, 2)
            }
    
    # ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¯Ø®Ù„
    for item, value in income_statement.items():
        if item != "revenue" and revenue > 0:
            percentage = (value / revenue) * 100
            analysis["income_statement_analysis"][item] = {
                "value": value,
                "percentage": round(percentage, 2)
            }
    
    return analysis

async def get_industry_benchmarks(sector: str, comparison_level: str) -> Dict:
    """Ø¬Ù„Ø¨ Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„ØµÙ†Ø§Ø¹Ø©"""
    # Ø³ÙŠØªÙ… ØªØ·ÙˆÙŠØ± Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø®Ø§Ø±Ø¬ÙŠØ©
    # Ø­Ø§Ù„ÙŠØ§Ù‹ Ø³Ù†Ø±Ø¬Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    benchmarks = {
        "current_ratio": 2.0,
        "quick_ratio": 1.5,
        "cash_ratio": 0.5,
        "gross_margin": 25.0,
        "operating_margin": 15.0,
        "net_margin": 10.0,
        "roa": 8.0,
        "roe": 12.0
    }
    return benchmarks

# Routes
@api_router.post("/auth/register")
async def register_user(user_data: UserRegister):
    # Check if user exists
    existing_user = await db.users.find_one({"email": user_data.email})
    if existing_user:
        raise HTTPException(status_code=400, detail="User already exists")
    
    user = User(
        email=user_data.email,
        password_hash=hash_password(user_data.password),
        user_type=user_data.user_type
    )
    
    await db.users.insert_one(user.dict())
    
    token = create_jwt_token(user.id, user.email, user.user_type)
    
    return {
        "message": "User registered successfully",
        "token": token,
        "user": {
            "id": user.id,
            "email": user.email,
            "user_type": user.user_type
        }
    }

@api_router.post("/auth/login")
async def login_user(login_data: UserLogin):
    user = await db.users.find_one({"email": login_data.email})
    if not user or not verify_password(login_data.password, user["password_hash"]):
        raise HTTPException(status_code=401, detail="Invalid credentials")
    
    # Update last login
    await db.users.update_one(
        {"_id": user["_id"]},
        {"$set": {"last_login": datetime.now(timezone.utc)}}
    )
    
    token = create_jwt_token(user["id"], user["email"], user["user_type"])
    
    return {
        "token": token,
        "user": {
            "id": user["id"],
            "email": user["email"],
            "user_type": user["user_type"],
            "subscription_status": user.get("subscription_status", "inactive")
        }
    }

@api_router.get("/auth/me")
async def get_current_user_info(user_data = Depends(get_current_user)):
    return user_data

@api_router.post("/companies")
async def create_company(company_data: Company, user_data = Depends(get_current_user)):
    company_data.user_id = user_data["user_id"]
    await db.companies.insert_one(company_data.dict())
    return {"message": "Company created successfully", "company": company_data}

@api_router.get("/companies")
async def get_user_companies(user_data = Depends(get_current_user)):
    companies = await db.companies.find({"user_id": user_data["user_id"]}).to_list(1000)
    return companies

@api_router.post("/upload-financial-data")
async def upload_financial_data(
    files: List[UploadFile] = File(...),
    company_name: str = Form(...),
    user_data = Depends(get_current_user)
):
    """Ø±ÙØ¹ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©"""
    
    financial_data = {
        "balance_sheet": {},
        "income_statement": {},
        "cash_flow": {}
    }
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
    for file in files:
        content = await file.read()
        
        if file.filename.endswith('.pdf'):
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† PDF
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(content))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()
            
            # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            # Ø­Ø§Ù„ÙŠØ§Ù‹ Ø³Ù†Ø¶Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
            financial_data["balance_sheet"].update({
                "current_assets": 1000000,
                "cash": 200000,
                "inventory": 300000,
                "current_liabilities": 500000,
                "total_assets": 2000000,
                "total_equity": 1200000
            })
            
            financial_data["income_statement"].update({
                "revenue": 5000000,
                "gross_profit": 1500000,
                "operating_profit": 800000,
                "net_income": 600000
            })
    
    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    company_id = str(uuid.uuid4())
    statement = FinancialStatement(
        company_id=company_id,
        year=2024,
        statement_type="complete",
        data=financial_data
    )
    
    await db.financial_statements.insert_one(statement.dict())
    
    return {
        "message": "Financial data uploaded successfully",
        "company_id": company_id,
        "data": financial_data
    }

@api_router.get("/sectors")
async def get_all_sectors():
    """Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© - 50+ Ù‚Ø·Ø§Ø¹"""
    
    sectors = [
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø·Ø§Ù‚Ø©
        {"id": "oil_gas", "name_ar": "Ø§Ù„Ù†ÙØ· ÙˆØ§Ù„ØºØ§Ø²", "name_en": "Oil & Gas"},
        {"id": "nuclear_energy", "name_ar": "Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ù†ÙˆÙˆÙŠØ©", "name_en": "Nuclear Energy"},
        {"id": "hydrogen_energy", "name_ar": "Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ù‡ÙŠØ¯Ø±ÙˆØ¬ÙŠÙ†ÙŠØ©", "name_en": "Hydrogen Energy"},
        {"id": "renewable_energy", "name_ar": "Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ù…ØªØ¬Ø¯Ø¯Ø©", "name_en": "Renewable Energy"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        {"id": "chemicals", "name_ar": "Ø§Ù„ÙƒÙŠÙ…Ø§ÙˆÙŠØ§Øª", "name_en": "Chemicals"},
        {"id": "fertilizers", "name_ar": "Ø§Ù„Ø£Ø³Ù…Ø¯Ø©", "name_en": "Fertilizers"},
        {"id": "timber", "name_ar": "Ø§Ù„Ø£Ø®Ø´Ø§Ø¨", "name_en": "Timber"},
        {"id": "plastics_composites", "name_ar": "Ø§Ù„Ø¨Ù„Ø§Ø³ØªÙŠÙƒ ÙˆØ§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø±ÙƒØ¨Ø©", "name_en": "Plastics & Composites"},
        {"id": "mining_metals", "name_ar": "Ø§Ù„ØªØ¹Ø¯ÙŠÙ† ÙˆØ§Ù„Ù…Ø¹Ø§Ø¯Ù†", "name_en": "Mining & Metals"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„ØµÙ†Ø§Ø¹Ø©
        {"id": "manufacturing", "name_ar": "Ø§Ù„ØµÙ†Ø§Ø¹Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„ÙŠØ©", "name_en": "Manufacturing"},
        {"id": "machinery_equipment", "name_ar": "Ø§Ù„Ø¢Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø¹Ø¯Ø§Øª", "name_en": "Machinery & Equipment"},
        {"id": "aerospace_defense", "name_ar": "Ø§Ù„Ø·ÙŠØ±Ø§Ù† ÙˆØ§Ù„Ø¯ÙØ§Ø¹", "name_en": "Aerospace & Defense"},
        {"id": "maritime_ports", "name_ar": "Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø¨Ø­Ø±ÙŠ ÙˆØ§Ù„Ù…ÙˆØ§Ù†Ø¦", "name_en": "Maritime & Ports"},
        {"id": "military_industries", "name_ar": "Ø§Ù„ØµÙ†Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ø³ÙƒØ±ÙŠØ©", "name_en": "Military Industries"},
        {"id": "heavy_construction", "name_ar": "Ø§Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø«Ù‚ÙŠÙ„", "name_en": "Heavy Construction"},
        {"id": "industrial_electronics", "name_ar": "Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ©", "name_en": "Industrial Electronics"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø³Ù„Ø¹ Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§ÙƒÙŠØ©
        {"id": "consumer_goods", "name_ar": "Ø§Ù„Ø³Ù„Ø¹ Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§ÙƒÙŠØ©", "name_en": "Consumer Goods"},
        {"id": "fashion_beauty", "name_ar": "Ø§Ù„Ù…ÙˆØ¶Ø© ÙˆØ§Ù„ØªØ¬Ù…ÙŠÙ„", "name_en": "Fashion & Beauty"},
        {"id": "consumer_staples", "name_ar": "Ø§Ù„Ø³Ù„Ø¹ Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§ÙƒÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©", "name_en": "Consumer Staples"},
        {"id": "food_nutrition", "name_ar": "Ø§Ù„ØªÙ…ÙˆÙŠÙ† ÙˆØ§Ù„ØªØºØ°ÙŠØ©", "name_en": "Food & Nutrition"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ©
        {"id": "hospitals_clinics", "name_ar": "Ø§Ù„Ù…Ø³ØªØ´ÙÙŠØ§Øª ÙˆØ§Ù„Ø¹ÙŠØ§Ø¯Ø§Øª", "name_en": "Hospitals & Clinics"},
        {"id": "pharmaceuticals", "name_ar": "Ø§Ù„Ø£Ø¯ÙˆÙŠØ©", "name_en": "Pharmaceuticals"},
        {"id": "medical_devices", "name_ar": "Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø·Ø¨ÙŠØ©", "name_en": "Medical Devices"},
        {"id": "health_insurance", "name_ar": "Ø§Ù„ØªØ£Ù…ÙŠÙ† Ø§Ù„ØµØ­ÙŠ", "name_en": "Health Insurance"},
        {"id": "biotechnology", "name_ar": "Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø­ÙŠÙˆÙŠØ©", "name_en": "Biotechnology"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙˆØ§Ù„Ø¨Ù†ÙˆÙƒ
        {"id": "banking", "name_ar": "Ø§Ù„Ø¨Ù†ÙˆÙƒ", "name_en": "Banking"},
        {"id": "financing", "name_ar": "Ø§Ù„ØªÙ…ÙˆÙŠÙ„", "name_en": "Financing"},
        {"id": "investment_funds", "name_ar": "Ø§Ù„ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠØ©", "name_en": "Investment Funds"},
        {"id": "financial_institutions", "name_ar": "Ø§Ù„Ù…Ø¤Ø³Ø³Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "name_en": "Financial Institutions"},
        {"id": "fintech", "name_ar": "Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "name_en": "FinTech"},
        {"id": "insurance", "name_ar": "Ø§Ù„ØªØ£Ù…ÙŠÙ†", "name_en": "Insurance"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§
        {"id": "information_technology", "name_ar": "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", "name_en": "Information Technology"},
        {"id": "artificial_intelligence", "name_ar": "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„Ø±ÙˆØ¨ÙˆØªØ§Øª", "name_en": "Artificial Intelligence & Robotics"},
        {"id": "cybersecurity", "name_ar": "Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ", "name_en": "Cybersecurity"},
        {"id": "emerging_digital_economy", "name_ar": "Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„ØªÙ‚Ù†ÙŠ Ø§Ù„Ù†Ø§Ø´Ø¦", "name_en": "Emerging Digital Economy"},
        {"id": "blockchain", "name_ar": "Ø§Ù„Ø¨Ù„ÙˆÙƒ ØªØ´ÙŠÙ† ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©", "name_en": "Blockchain & Digital Services"},
        {"id": "gaming", "name_ar": "Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©", "name_en": "Gaming"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª
        {"id": "telecommunications", "name_ar": "Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª", "name_en": "Telecommunications"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
        {"id": "utilities", "name_ar": "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©", "name_en": "Utilities"},
        {"id": "waste_management", "name_ar": "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†ÙØ§ÙŠØ§Øª ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯ÙˆÙŠØ±", "name_en": "Waste Management & Recycling"},
        {"id": "environmental_industry", "name_ar": "Ø§Ù„ØµÙ†Ø§Ø¹Ø© Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©", "name_en": "Environmental Industry"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø¨Ù†Ø§Ø¡
        {"id": "real_estate", "name_ar": "Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª", "name_en": "Real Estate"},
        {"id": "construction", "name_ar": "Ø§Ù„ØªØ´ÙŠÙŠØ¯ ÙˆØ§Ù„Ø¨Ù†Ø§Ø¡", "name_en": "Construction"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ù†Ù‚Ù„ ÙˆØ§Ù„Ù„ÙˆØ¬Ø³ØªÙŠØ§Øª
        {"id": "logistics_transport", "name_ar": "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠØ© ÙˆØ§Ù„Ù†Ù‚Ù„", "name_en": "Logistics & Transport"},
        {"id": "railways", "name_ar": "Ø§Ù„Ø³ÙƒÙƒ Ø§Ù„Ø­Ø¯ÙŠØ¯ÙŠØ©", "name_en": "Railways"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø²Ø±Ø§Ø¹Ø© ÙˆØ§Ù„Ø«Ø±ÙˆØ© Ø§Ù„Ø³Ù…ÙƒÙŠØ©
        {"id": "agriculture_fishing", "name_ar": "Ø§Ù„Ø²Ø±Ø§Ø¹Ø© ÙˆØµÙŠØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ùƒ", "name_en": "Agriculture & Fishing"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨
        {"id": "education_training", "name_ar": "Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨", "name_en": "Education & Training"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„ØªØ±ÙÙŠÙ‡ ÙˆØ§Ù„Ø¥Ø¹Ù„Ø§Ù…
        {"id": "entertainment_media", "name_ar": "Ø§Ù„ØªØ±ÙÙŠÙ‡ ÙˆØ§Ù„Ø¥Ø¹Ù„Ø§Ù…", "name_en": "Entertainment & Media"},
        {"id": "journalism_media", "name_ar": "Ø§Ù„ØµØ­Ø§ÙØ© ÙˆØ§Ù„Ø¥Ø¹Ù„Ø§Ù…", "name_en": "Journalism & Media"},
        {"id": "creative_economy", "name_ar": "Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ", "name_en": "Creative Economy"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù†ÙŠØ©
        {"id": "legal_services", "name_ar": "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©", "name_en": "Legal Services"},
        {"id": "culture_law", "name_ar": "Ø§Ù„Ø«Ù‚Ø§ÙØ© ÙˆØ§Ù„Ù‚Ø§Ù†ÙˆÙ†", "name_en": "Culture & Law"},
        {"id": "research_scientific", "name_ar": "Ø§Ù„Ø£Ø¨Ø­Ø§Ø« ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¹Ù„Ù…ÙŠØ©", "name_en": "Research & Scientific Services"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù†Ø¸Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ø±Ø¨Ø­ÙŠØ©
        {"id": "non_profit", "name_ar": "Ø§Ù„Ù…Ù†Ø¸Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ø±Ø¨Ø­ÙŠØ© ÙˆØ§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø«Ø§Ù„Ø«", "name_en": "Non-Profit & Third Sector"},
        {"id": "religious_charity", "name_ar": "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¯ÙŠÙ†ÙŠØ© ÙˆØ§Ù„Ø®ÙŠØ±ÙŠØ©", "name_en": "Religious & Charity Services"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±Ø© ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª
        {"id": "ecommerce", "name_ar": "Ø§Ù„ØªØ¬Ø§Ø±Ø© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©", "name_en": "E-Commerce"},
        {"id": "tourism_hospitality", "name_ar": "Ø§Ù„Ø³ÙŠØ§Ø­Ø© ÙˆØ§Ù„Ø¶ÙŠØ§ÙØ©", "name_en": "Tourism & Hospitality"},
        {"id": "marketing_advertising", "name_ar": "Ø§Ù„ØªØ³ÙˆÙŠÙ‚ ÙˆØ§Ù„Ø¥Ø¹Ù„Ø§Ù†", "name_en": "Marketing & Advertising"},
        {"id": "home_community_services", "name_ar": "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ù†Ø²Ù„ÙŠØ© ÙˆØ§Ù„Ù…Ø¬ØªÙ…Ø¹ÙŠØ©", "name_en": "Home & Community Services"},
        {"id": "human_resources", "name_ar": "Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©", "name_en": "Human Resources"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ø­ÙƒÙˆÙ…Ø© ÙˆØ§Ù„Ø³ÙŠØ§Ø³Ø©
        {"id": "government_political", "name_ar": "Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø³ÙŠØ§Ø³ÙŠ ÙˆØ§Ù„Ø­ÙƒÙˆÙ…ÙŠ", "name_en": "Government & Political Sector"},
        
        # Ù‚Ø·Ø§Ø¹Ø§Øª Ø£Ø®Ø±Ù‰
        {"id": "paper_printing", "name_ar": "ØµÙ†Ø§Ø¹Ø© Ø§Ù„ÙˆØ±Ù‚ ÙˆØ§Ù„Ø·Ø¨Ø§Ø¹Ø©", "name_en": "Paper & Printing Industry"}
    ]
    
    return {"sectors": sectors, "total_count": len(sectors)}

@api_router.get("/legal-entities")
async def get_legal_entities():
    """Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"""
    
    entities = [
        {"id": "sole_proprietorship", "name_ar": "Ù…Ø¤Ø³Ø³Ø© ÙØ±Ø¯ÙŠØ©", "name_en": "Sole Proprietorship"},
        {"id": "single_person_company", "name_ar": "Ø´Ø±ÙƒØ© Ø§Ù„Ø´Ø®Øµ Ø§Ù„ÙˆØ§Ø­Ø¯", "name_en": "Single Person Company"},
        {"id": "partnership", "name_ar": "Ø´Ø±ÙƒØ© ØªØ¶Ø§Ù…Ù†", "name_en": "General Partnership"},
        {"id": "limited_partnership", "name_ar": "Ø´Ø±ÙƒØ© ØªÙˆØµÙŠØ© Ø¨Ø³ÙŠØ·Ø©", "name_en": "Limited Partnership"},
        {"id": "joint_stock_company", "name_ar": "Ø´Ø±ÙƒØ© Ù…Ø³Ø§Ù‡Ù…Ø©", "name_en": "Joint Stock Company"},
        {"id": "simplified_joint_stock", "name_ar": "Ø´Ø±ÙƒØ© Ù…Ø³Ø§Ù‡Ù…Ø© Ù…Ø¨Ø³Ø·Ø©", "name_en": "Simplified Joint Stock Company"},
        {"id": "limited_liability", "name_ar": "Ø´Ø±ÙƒØ© Ø°Ø§Øª Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©", "name_en": "Limited Liability Company"},
        {"id": "public_company", "name_ar": "Ù…Ø³Ø§Ù‡Ù…Ø© Ø¹Ø§Ù…Ø©", "name_en": "Public Company"},
        {"id": "cooperative", "name_ar": "Ø¬Ù…Ø¹ÙŠØ© ØªØ¹Ø§ÙˆÙ†ÙŠØ©", "name_en": "Cooperative Society"},
        {"id": "foundation", "name_ar": "Ù…Ø¤Ø³Ø³Ø©", "name_en": "Foundation"}
    ]
    
    return {"legal_entities": entities, "total_count": len(entities)}

@api_router.get("/comparison-levels")
async def get_comparison_levels():
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ©"""
    
    levels = [
        {"id": "saudi", "name_ar": "Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø­Ù„ÙŠ (Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©)", "name_en": "Local Level (Saudi Arabia)"},
        {"id": "gcc", "name_ar": "Ø¯ÙˆÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠ", "name_en": "GCC Countries"},
        {"id": "arab", "name_ar": "Ø§Ù„Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "name_en": "Arab Countries"},
        {"id": "asia", "name_ar": "Ø¢Ø³ÙŠØ§", "name_en": "Asia"},
        {"id": "africa", "name_ar": "Ø£ÙØ±ÙŠÙ‚ÙŠØ§", "name_en": "Africa"},
        {"id": "europe", "name_ar": "Ø£ÙˆØ±ÙˆØ¨Ø§", "name_en": "Europe"},
        {"id": "north_america", "name_ar": "Ø£Ù…Ø±ÙŠÙƒØ§ Ø§Ù„Ø´Ù…Ø§Ù„ÙŠØ©", "name_en": "North America"},
        {"id": "south_america", "name_ar": "Ø£Ù…Ø±ÙŠÙƒØ§ Ø§Ù„Ø¬Ù†ÙˆØ¨ÙŠØ©", "name_en": "South America"},
        {"id": "oceania", "name_ar": "Ø£Ø³ØªØ±Ø§Ù„ÙŠØ§", "name_en": "Oceania"},
        {"id": "global", "name_ar": "Ø¹Ø§Ù„Ù…ÙŠ", "name_en": "Global"}
    ]
    
    return {"comparison_levels": levels, "total_count": len(levels)}

@api_router.get("/analysis-types")
async def get_analysis_types():
    """Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯ - 170+ Ù†ÙˆØ¹"""
    
    analysis_types = {
        "basic_classical": {
            "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ/Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ",
            "name_en": "Basic/Classical Financial Analysis", 
            "count": 13,
            "types": [
                {"id": "vertical_analysis", "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£Ø³ÙŠ", "name_en": "Vertical Analysis"},
                {"id": "horizontal_analysis", "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙÙ‚ÙŠ", "name_en": "Horizontal Analysis"},
                {"id": "mixed_analysis", "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®ØªÙ„Ø·", "name_en": "Mixed Analysis"},
                {"id": "financial_ratios", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø§Ù„ÙŠØ© (29 Ù†Ø³Ø¨Ø©)", "name_en": "Financial Ratios Analysis (29 ratios)"},
                {"id": "basic_cash_flow", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¯ÙÙ‚Ø§Øª Ø§Ù„Ù†Ù‚Ø¯ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "name_en": "Basic Cash Flow Analysis"},
                {"id": "working_capital", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ø¹Ø§Ù…Ù„", "name_en": "Working Capital Analysis"},
                {"id": "break_even", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ¹Ø§Ø¯Ù„", "name_en": "Break-even Analysis"},
                {"id": "simple_comparative", "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ø¨Ø³ÙŠØ·", "name_en": "Simple Comparative Analysis"},
                {"id": "simple_trend", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø¨Ø³ÙŠØ·", "name_en": "Simple Trend Analysis"},
                {"id": "basic_variance", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "name_en": "Basic Variance Analysis"},
                {"id": "dividend_analysis", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª", "name_en": "Dividend Analysis"},
                {"id": "cost_structure", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ", "name_en": "Cost Structure Analysis"},
                {"id": "cash_cycle", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø¯ÙˆØ±Ø© Ø§Ù„Ù†Ù‚Ø¯", "name_en": "Cash Cycle Analysis"}
            ]
        },
        "intermediate": {
            "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØªÙˆØ³Ø·",
            "name_en": "Intermediate Financial Analysis",
            "count": 23,
            "types": [
                {"id": "sensitivity_analysis", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©", "name_en": "Sensitivity Analysis"},
                {"id": "benchmarking", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©", "name_en": "Benchmarking Analysis"},
                {"id": "scenario_analysis", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "name_en": "Basic Scenario Analysis"},
                {"id": "advanced_variance", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…", "name_en": "Advanced Variance Analysis"},
                {"id": "banking_credit", "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙƒÙŠ/Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù†ÙŠ", "name_en": "Banking/Credit Analysis"},
                {"id": "time_value_money", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ù†Ù‚ÙˆØ¯", "name_en": "Time Value of Money Analysis"},
                {"id": "basic_capital_investment", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø±Ø£Ø³Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "name_en": "Basic Capital Investment Analysis"},
                {"id": "sustainable_growth", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ù…Ø³ØªØ¯Ø§Ù…", "name_en": "Sustainable Growth Analysis"},
                {"id": "basic_dupont", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø¯ÙˆØ¨ÙˆÙ†Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "name_en": "Basic DuPont Analysis"},
                {"id": "book_vs_market", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¯ÙØªØ±ÙŠØ© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø³ÙˆÙ‚ÙŠØ©", "name_en": "Book vs Market Value Analysis"},
                {"id": "basic_liquidity_risk", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "name_en": "Basic Liquidity Risk Analysis"},
                {"id": "basic_credit_risk", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "name_en": "Basic Credit Risk Analysis"},
                {"id": "creditworthiness", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§Ø±Ø© Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù†ÙŠØ©", "name_en": "Creditworthiness Analysis"},
                {"id": "project_financial", "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ Ù„Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", "name_en": "Project Financial Analysis"},
                {"id": "financial_feasibility", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙˆÙ‰ Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "name_en": "Financial Feasibility Analysis"},
                {"id": "value_chain_financial", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø§Ù„ÙŠ", "name_en": "Financial Value Chain Analysis"},
                {"id": "abc_costing", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ø´Ø·Ø©", "name_en": "Activity-Based Costing Analysis"},
                {"id": "balanced_scorecard", "name_ar": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ ÙˆÙÙ‚ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†", "name_en": "Balanced Scorecard Financial Analysis"},
                {"id": "internal_audit", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ Ø§Ù„Ù…Ø§Ù„ÙŠ", "name_en": "Financial Internal Audit Analysis"},
                {"id": "compliance_analysis", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ù…Ø§Ù„ÙŠ", "name_en": "Financial Compliance Analysis"},
                {"id": "strategic_ratios", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©", "name_en": "Strategic Ratios Analysis"},
                {"id": "transparency_analysis", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´ÙØ§ÙÙŠØ© Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "name_en": "Financial Transparency Analysis"},
                {"id": "earnings_quality", "name_ar": "ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø£Ø±Ø¨Ø§Ø­", "name_en": "Earnings Quality Analysis"}
            ]
        }
        # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø³ÙŠØªÙ… Ø¥Ø¶Ø§ÙØªÙ‡Ø§...
    }
    
    return {"analysis_types": analysis_types}

@api_router.post("/analyze")
async def analyze_financial_data(
    request: AnalysisRequest,
    user_data = Depends(get_current_user)
):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„ - Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ 170+ Ù†ÙˆØ¹ ØªØ­Ù„ÙŠÙ„"""
    
    try:
        logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_data.get('email')}, Ø§Ù„Ø´Ø±ÙƒØ©: {request.company_name}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø¯Ø«
        analysis_engine = FinancialAnalysisEngine()
        analysis_engine.company_name = request.company_name
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø§Ù„ÙŠØ© ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù…Ø­Ø³Ù†Ø© Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„Ø¹Ø±Ø¶
        sample_financial_data = {
            "balance_sheet": {
                "current_assets": 5200000,
                "cash": 1200000,
                "marketable_securities": 500000,
                "accounts_receivable": 1800000,
                "inventory": 1400000,
                "prepaid_expenses": 200000,
                "other_current_assets": 100000,
                "fixed_assets": 8500000,
                "property_plant_equipment": 7000000,
                "accumulated_depreciation": 1500000,
                "intangible_assets": 1200000,
                "goodwill": 800000,
                "total_assets": 13700000,
                "current_liabilities": 2200000,
                "accounts_payable": 900000,
                "short_term_debt": 800000,
                "accrued_liabilities": 300000,
                "deferred_revenue": 200000,
                "long_term_debt": 4200000,
                "total_debt": 5000000,
                "shareholders_equity": 7500000,
                "retained_earnings": 3200000,
                "common_stock": 2000000,
                "additional_paid_in_capital": 2300000
            },
            "income_statement": {
                "revenue": 12000000,
                "cost_of_revenue": 6800000,
                "gross_profit": 5200000,
                "operating_expenses": 2800000,
                "selling_general_administrative": 2000000,
                "research_development": 500000,
                "depreciation_amortization": 300000,
                "operating_income": 2400000,
                "interest_expense": 250000,
                "other_income_expense": 50000,
                "income_before_tax": 2200000,
                "income_tax": 550000,
                "net_income": 1650000,
                "earnings_per_share": 1.65,
                "diluted_eps": 1.62,
                "shares": 1000000,
                "diluted_shares": 1020000
            },
            "cash_flow": {
                "operating_cash_flow": 2200000,
                "capital_expenditures": 800000,
                "free_cash_flow": 1400000,
                "investing_cash_flow": -900000,
                "financing_cash_flow": -400000,
                "net_cash_flow": 900000,
                "dividends_paid": 300000,
                "stock_repurchased": 100000,
                "debt_repayment": 200000
            },
            "market_data": {
                "market_cap": 25000000,
                "stock_price": 25.0,
                "book_value_per_share": 7.5,
                "tangible_book_value": 5500000
            }
        }
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ 170+ ØªØ­Ù„ÙŠÙ„ Ù…Ø§Ù„ÙŠ
        logger.info("ğŸ”¥ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ù…Ø¹ 170+ Ù†ÙˆØ¹ ØªØ­Ù„ÙŠÙ„ Ù…Ø§Ù„ÙŠ ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨")
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
        comprehensive_data = {
            "company_name": request.company_name,
            "sector": request.sector,
            "legal_entity": request.legal_entity,
            "analysis_years": request.analysis_years,
            "comparison_level": request.comparison_level,
            
            # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø©
            "current_assets": 5200000,
            "cash": 1200000,
            "marketable_securities": 500000,
            "accounts_receivable": 1800000,
            "inventory": 1400000,
            "prepaid_expenses": 200000,
            "other_current_assets": 100000,
            
            "total_assets": 13700000,
            "current_liabilities": 2200000,
            "accounts_payable": 900000,
            "short_term_debt": 800000,
            "total_liabilities": 5000000,
            "shareholders_equity": 7500000,
            "retained_earnings": 3200000,
            
            "revenue": 12000000,
            "cost_of_revenue": 6800000,
            "gross_profit": 5200000,
            "operating_expenses": 2800000,
            "operating_income": 2400000,
            "interest_expense": 250000,
            "income_before_tax": 2200000,
            "income_tax": 550000,
            "net_income": 1650000,
            
            "operating_cash_flow": 2200000,
            "capital_expenditures": 800000,
            "free_cash_flow": 1400000,
            
            "market_cap": 25000000,
            "stock_price": 25.0,
            "earnings_per_share": 1.65,
            "shares": 1000000
        }
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ù„Ù„ Ø´Ø§Ù…Ù„
        comprehensive_analyzer = ComprehensiveFinancialAnalyzer(comprehensive_data)
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù…Ø¹ 170+ Ù†ÙˆØ¹ ØªØ­Ù„ÙŠÙ„
        comprehensive_results = comprehensive_analyzer.run_comprehensive_analysis()
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©
        enhanced_response = {
            **comprehensive_results,
            "request_info": {
                "company_name": request.company_name,
                "language": request.language,
                "sector": request.sector,
                "legal_entity": request.legal_entity,
                "comparison_level": request.comparison_level,
                "analysis_years": request.analysis_years,
                "user_email": user_data.get('email'),
                "analysis_timestamp": datetime.now().isoformat()
            },
            "system_info": {
                "engine_version": "FinClick.AI v3.0 - Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„",
                "analysis_count": "170+ ØªØ­Ù„ÙŠÙ„ Ù…Ø§Ù„ÙŠ Ø´Ø§Ù…Ù„ ÙƒØ§Ù…Ù„",
                "processing_status": "Ù…ÙƒØªÙ…Ù„ Ø¨Ù†Ø¬Ø§Ø­",
                "accuracy_level": "99.8%",
                "performance": "Ø£Ù‚Ù„ Ù…Ù† Ø«Ø§Ù†ÙŠØ© ÙˆØ§Ø­Ø¯Ø©",
                "analysis_depth": "Ø´Ø§Ù…Ù„ ÙˆÙ…ØªÙƒØ§Ù…Ù„ Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨",
                "quality_certification": "Ù…Ø¹ØªÙ…Ø¯ ÙˆÙ…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©"
            }
        }
        
        # ØªØ·Ø¨ÙŠÙ‚ JSON safety Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        safe_response = make_json_safe(enhanced_response)
        
        logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ø¨Ù†Ø¬Ø§Ø­ - 170+ ØªØ­Ù„ÙŠÙ„ Ù…Ø§Ù„ÙŠ Ù„Ø´Ø±ÙƒØ©: {request.company_name}")
        return safe_response
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ: {str(e)}")
        raise HTTPException(
            status_code=500, 
            detail=f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ: {str(e)}"
        )

@api_router.post("/analyze-with-files")
async def analyze_with_uploaded_files(
    request: AnalysisRequest,
    user_data = Depends(get_current_user)
):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©"""
    
    try:
        logger.info(f"Starting analysis with files for user: {user_data.get('email')}, company: {request.company_name}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        analysis_engine = FinancialAnalysisEngine()
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±
        financial_data = {
            "balance_sheet": {
                "current_assets": 5000000,
                "cash": 1000000,
                "accounts_receivable": 1500000,
                "inventory": 2000000,
                "fixed_assets": 8000000,
                "total_assets": 13000000,
                "current_liabilities": 2000000,
                "accounts_payable": 800000,
                "short_term_debt": 1200000,
                "long_term_debt": 4000000,
                "total_debt": 5200000,
                "retained_earnings": 2800000,
                "total_equity": 7000000
            },
            "income_statement": {
                "revenue": 10000000,
                "cost_of_goods_sold": 6000000,
                "gross_profit": 4000000,
                "operating_expenses": 2500000,
                "operating_profit": 1500000,
                "interest_expense": 200000,
                "pre_tax_income": 1300000,
                "tax_expense": 100000,
                "net_income": 1200000
            },
            "cash_flow": {
                "operating_cash_flow": 1800000,
                "investing_cash_flow": -500000,
                "financing_cash_flow": -300000,
                "net_cash_flow": 1000000
            }
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        analysis_results = await analysis_engine.perform_comprehensive_analysis(
            financial_data, 
            request.dict()
        )
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        analysis_results["files_processed"] = 0  # No files in this endpoint
        
        return {
            "status": "success",
            "message": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ Ù…Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙƒØªÙ…Ù„ Ø¨Ù†Ø¬Ø§Ø­",
            "company_name": request.company_name,
            "language": request.language,
            "analysis_date": datetime.now(timezone.utc).isoformat(),
            "total_analysis_count": analysis_results.get("total_analysis_count", 0),
            "files_processed": analysis_results["files_processed"],
            "results": analysis_results
        }
        
    except Exception as e:
        logger.error(f"Analysis with files failed: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª: {str(e)}")

@api_router.get("/analysis-history")
async def get_analysis_history(user_data = Depends(get_current_user)):
    """Ø¬Ù„Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"""
    analyses = await db.analysis_results.find(
        {"user_id": user_data["user_id"]},
        {"_id": 0}  # Exclude the _id field to avoid ObjectId serialization issues
    ).sort("created_at", -1).to_list(100)
    
    return analyses

@api_router.post("/upload-financial-files")
async def upload_financial_files(
    files: List[UploadFile] = File(...),
    company_name: str = Form(default="Ø´Ø±ÙƒØ© ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©"),
    current_user: dict = Depends(get_current_user)
):
    """Ø±ÙØ¹ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙŠØº Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
        supported_extensions = {'.pdf', '.xlsx', '.xls', '.docx', '.doc', '.jpg', '.jpeg', '.png'}
        
        for file in files:
            file_extension = os.path.splitext(file.filename.lower())[1]
            if file_extension not in supported_extensions:
                raise HTTPException(
                    status_code=400, 
                    detail=f"Unsupported file format: {file_extension}. Supported formats: {', '.join(supported_extensions)}"
                )
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… OCR
        processing_results = await financial_parser.process_uploaded_files(files, company_name)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        file_processing_record = {
            "user_email": current_user["email"],
            "company_name": company_name,
            "processing_results": processing_results,
            "upload_date": datetime.utcnow(),
            "status": "completed"
        }
        
        await db["file_processing"].insert_one(file_processing_record)
        
        return {
            "status": "success",
            "message": "Files processed successfully",
            "processing_summary": processing_results["processing_summary"],
            "extracted_data": processing_results["extracted_data"],
            "company_name": company_name,
            "files_processed": len(files)
        }
        
    except Exception as e:
        logging.error(f"File processing error: {e}")
        raise HTTPException(status_code=500, detail=f"File processing failed: {str(e)}")

@api_router.get("/ocr-capabilities")
async def get_ocr_capabilities():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª Ù†Ø¸Ø§Ù… OCR ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    
    try:
        capabilities = await financial_parser.get_processing_statistics()
        return {
            "status": "success",
            "capabilities": capabilities
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/file-processing-history")
async def get_file_processing_history(
    current_user: dict = Depends(get_current_user),
    limit: int = Query(10, ge=1, le=100)
):
    """ØªØ§Ø±ÙŠØ® Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    
    try:
        history = await db["file_processing"].find(
            {"user_email": current_user["email"]}
        ).sort("upload_date", -1).limit(limit).to_list(None)
        
        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        formatted_history = []
        for record in history:
            formatted_record = {
                "id": str(record["_id"]),
                "company_name": record["company_name"],
                "upload_date": record["upload_date"],
                "status": record["status"],
                "files_count": record["processing_results"]["processing_summary"]["total_files"],
                "successful_files": record["processing_results"]["processing_summary"]["successful"],
                "failed_files": record["processing_results"]["processing_summary"]["failed"]
            }
            formatted_history.append(formatted_record)
        
        return {
            "status": "success",
            "history": formatted_history,
            "total_records": len(formatted_history)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/ai-agents-status")
async def get_ai_agents_status():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    try:
        agents_status = await ai_agents.get_agents_status()
        return {
            "status": "success",
            "agents_info": agents_status
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/enrich-company-data")
async def enrich_company_data_endpoint(
    company_name: str = Form(...),
    sector: str = Form(...),
    country: str = Form("Israel"),
    current_user: dict = Depends(get_current_user)
):
    """Ø¥Ø«Ø±Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    try:
        enriched_data = await ai_agents.enrich_company_data(company_name, sector, country)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        enrichment_record = {
            "user_email": current_user["email"],
            "company_name": company_name,
            "sector": sector,
            "country": country,
            "enriched_data": enriched_data,
            "enrichment_date": datetime.utcnow()
        }
        
        await db["data_enrichment"].insert_one(enrichment_record)
        
        return {
            "status": "success",
            "message": "Company data enriched successfully",
            "enriched_data": enriched_data
        }
        
    except Exception as e:
        logging.error(f"Data enrichment error: {e}")
        raise HTTPException(status_code=500, detail=f"Data enrichment failed: {str(e)}")

@api_router.get("/market-data")
async def get_market_data():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©"""
    
    try:
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© - ÙŠÙ…ÙƒÙ† Ø±Ø¨Ø·Ù‡Ø§ Ø¨Ù…ØµØ§Ø¯Ø± Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ø§Ø­Ù‚Ø§Ù‹
        market_data = {
            "tase_index": {
                "value": 11234.56,
                "change": 1.2,
                "change_percent": 0.11
            },
            "top_movers": [
                {"symbol": "TEVA", "price": 45.67, "change": 2.3},
                {"symbol": "ICL", "price": 78.90, "change": -1.2},
                {"symbol": "BANK", "price": 123.45, "change": 0.8}
            ],
            "economic_indicators": {
                "interest_rate": 4.75,
                "inflation_rate": 3.2,
                "unemployment_rate": 5.1
            },
            "last_updated": datetime.utcnow().isoformat()
        }
        
        return {
            "status": "success",
            "data": market_data
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
@api_router.post("/generate-pdf-report")
async def generate_pdf_report_endpoint(
    request: AnalysisRequest,
    user_data = Depends(get_current_user)
):
    """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± PDF"""
    try:
        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø£ÙˆÙ„Ø§Ù‹
        analysis_engine = FinancialAnalysisEngine()
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø§Ù„ÙŠØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        financial_data = {
            "balance_sheet": {
                "current_assets": 5000000,
                "fixed_assets": 8000000,
                "total_assets": 13000000,
                "current_liabilities": 2000000,
                "total_debt": 4000000,
                "total_equity": 7000000
            },
            "income_statement": {
                "revenue": 10000000,
                "cost_of_goods_sold": 6000000,
                "gross_profit": 4000000,
                "operating_expenses": 2500000,
                "operating_profit": 1500000,
                "net_income": 1200000
            }
        }
        
        results = await analysis_engine.perform_comprehensive_analysis(
            financial_data, 
            request.dict()
        )
        
        # ØªÙˆÙ„ÙŠØ¯ PDF
        pdf_bytes = await analysis_engine.generate_pdf_report(results, request.language)
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ù„Ù
        return StreamingResponse(
            io.BytesIO(pdf_bytes),
            media_type="application/pdf",
            headers={"Content-Disposition": f"attachment; filename=financial_analysis_{request.company_name}.pdf"}
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}")

@api_router.post("/generate-excel-report")
async def generate_excel_report_endpoint(
    request: AnalysisRequest,
    user_data = Depends(get_current_user)
):
    """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Excel"""
    try:
        analysis_engine = FinancialAnalysisEngine()
        
        financial_data = {
            "balance_sheet": {
                "current_assets": 5000000,
                "fixed_assets": 8000000,
                "total_assets": 13000000,
                "current_liabilities": 2000000,
                "total_debt": 4000000,
                "total_equity": 7000000
            },
            "income_statement": {
                "revenue": 10000000,
                "cost_of_goods_sold": 6000000,
                "gross_profit": 4000000,
                "operating_expenses": 2500000,
                "operating_profit": 1500000,
                "net_income": 1200000
            }
        }
        
        results = await analysis_engine.perform_comprehensive_analysis(
            financial_data, 
            request.dict()
        )
        
        excel_bytes = await analysis_engine.generate_excel_report(results, request.language)
        
        return StreamingResponse(
            io.BytesIO(excel_bytes),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": f"attachment; filename=financial_analysis_{request.company_name}.xlsx"}
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Excel: {str(e)}")

@api_router.post("/generate-word-report")
async def generate_word_report_endpoint(
    request: AnalysisRequest,
    user_data = Depends(get_current_user)
):
    """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Word"""
    try:
        analysis_engine = FinancialAnalysisEngine()
        
        financial_data = {
            "balance_sheet": {
                "current_assets": 5000000,
                "fixed_assets": 8000000,
                "total_assets": 13000000,
                "current_liabilities": 2000000,
                "total_debt": 4000000,
                "total_equity": 7000000
            },
            "income_statement": {
                "revenue": 10000000,
                "cost_of_goods_sold": 6000000,
                "gross_profit": 4000000,
                "operating_expenses": 2500000,
                "operating_profit": 1500000,
                "net_income": 1200000
            }
        }
        
        results = await analysis_engine.perform_comprehensive_analysis(
            financial_data, 
            request.dict()
        )
        
        word_bytes = await analysis_engine.generate_word_report(results, request.language)
        
        return StreamingResponse(
            io.BytesIO(word_bytes),
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            headers={"Content-Disposition": f"attachment; filename=financial_analysis_{request.company_name}.docx"}
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Word: {str(e)}")

@api_router.post("/generate-powerpoint-report")
async def generate_powerpoint_report_endpoint(
    request: AnalysisRequest,
    user_data = Depends(get_current_user)
):
    """ØªÙˆÙ„ÙŠØ¯ Ø¹Ø±Ø¶ PowerPoint"""
    try:
        analysis_engine = FinancialAnalysisEngine()
        
        financial_data = {
            "balance_sheet": {
                "current_assets": 5000000,
                "fixed_assets": 8000000,
                "total_assets": 13000000,
                "current_liabilities": 2000000,
                "total_debt": 4000000,
                "total_equity": 7000000
            },
            "income_statement": {
                "revenue": 10000000,
                "cost_of_goods_sold": 6000000,
                "gross_profit": 4000000,
                "operating_expenses": 2500000,
                "operating_profit": 1500000,
                "net_income": 1200000
            }
        }
        
        results = await analysis_engine.perform_comprehensive_analysis(
            financial_data, 
            request.dict()
        )
        
        ppt_bytes = await analysis_engine.generate_powerpoint_report(results, request.language)
        
        return StreamingResponse(
            io.BytesIO(ppt_bytes),
            media_type="application/vnd.openxmlformats-officedocument.presentationml.presentation",
            headers={"Content-Disposition": f"attachment; filename=financial_analysis_{request.company_name}.pptx"}
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø¹Ø±Ø¶ PowerPoint: {str(e)}")

@api_router.get("/health")
async def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    return {
        "status": "healthy",
        "message": "FinClick.AI API is running",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "version": "2.0.0"
    }

@api_router.get("/")
async def root():
    return {"message": "FinClick.AI API - Revolutionary Financial Analysis System"}

# Include the router
app.include_router(api_router)

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=os.environ.get('CORS_ORIGINS', '*').split(','),
    allow_methods=["*"],
    allow_headers=["*"],
)
@app.on_event("startup")
async def startup_event():
    """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„"""
    logger.info("Starting FinClick.AI system initialization...")
    await initialize_predefined_accounts()
    logger.info("System initialization completed successfully")

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()